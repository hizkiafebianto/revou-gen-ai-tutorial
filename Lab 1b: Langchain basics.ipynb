{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecc7e592",
   "metadata": {},
   "source": [
    "# Lab 1b: Langchain Basics\n",
    "\n",
    "In this lab, you will learn about LangChain — an open-source framework that helps developers build powerful applications using large language models (LLMs) like OpenAI's GPT. You'll start by installing the necessary packages, then explore chat models and basic tool usage, which will serve as a foundation for building AI agents in later labs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9194083b",
   "metadata": {},
   "source": [
    "## Installing LangChain\n",
    "We'll start by installing the langchain package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8db5c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/ed/5c/5c0be747261e1f8129b875fa3bfea736bc5fe17652f9d5e15ca118571b6f/langchain-0.3.25-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.58 (from langchain)\n",
      "  Obtaining dependency information for langchain-core<1.0.0,>=0.3.58 from https://files.pythonhosted.org/packages/c9/91/454a94275d323c0969e1f17a293cc87cb1398ab2d73f7db0a5de7883f2a9/langchain_core-0.3.58-py3-none-any.whl.metadata\n",
      "  Downloading langchain_core-0.3.58-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Obtaining dependency information for langchain-text-splitters<1.0.0,>=0.3.8 from https://files.pythonhosted.org/packages/8b/a3/3696ff2444658053c01b6b7443e761f28bb71217d82bb89137a978c5f66f/langchain_text_splitters-0.3.8-py3-none-any.whl.metadata\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Obtaining dependency information for langsmith<0.4,>=0.1.17 from https://files.pythonhosted.org/packages/89/8e/e8a58e0abaae3f3ac4702e9ca35d1fc6159711556b64ffd0e247771a3f12/langsmith-0.3.42-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.3.42-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.11/site-packages (from langchain) (2.11.4)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Obtaining dependency information for SQLAlchemy<3,>=1.4 from https://files.pythonhosted.org/packages/77/0f/dcf7bba95f847aec72f638750747b12d37914f71c8cc7c133cf326ab945c/sqlalchemy-2.0.40-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading sqlalchemy-2.0.40-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Obtaining dependency information for requests<3,>=2 from https://files.pythonhosted.org/packages/f9/9b/335f9764261e915ed497fcdeb11df5dfd6f7bf257d4a6a2a686d80da4d54/requests-2.32.3-py3-none-any.whl.metadata\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Obtaining dependency information for PyYAML>=5.3 from https://files.pythonhosted.org/packages/8b/62/b9faa998fd185f65c1371643678e4d58254add437edb764a08c5a98fb986/PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Obtaining dependency information for tenacity!=8.4.0,<10.0.0,>=8.1.0 from https://files.pythonhosted.org/packages/e5/30/643397144bfbfec6f6ef821f36f33e57d35946c44a2352d3c9f0ae847619/tenacity-9.1.2-py3-none-any.whl.metadata\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Obtaining dependency information for packaging<25,>=23.2 from https://files.pythonhosted.org/packages/88/ef/eb23f262cca3c0c4eb7ab1933c3b1f03d021f2c48f54763065b6f0e321be/packaging-24.2-py3-none-any.whl.metadata\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Obtaining dependency information for orjson<4.0.0,>=3.9.14 from https://files.pythonhosted.org/packages/97/c7/c54a948ce9a4278794f669a353551ce7db4ffb656c69a6e1f2264d563e50/orjson-3.10.18-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata\n",
      "  Downloading orjson-3.10.18-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Obtaining dependency information for requests-toolbelt<2.0.0,>=1.0.0 from https://files.pythonhosted.org/packages/3f/51/d4db610ef29373b879047326cbf6fa98b6c1969d6f6dc423279de2b1be2c/requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Obtaining dependency information for zstandard<0.24.0,>=0.23.0 from https://files.pythonhosted.org/packages/e8/46/66d5b55f4d737dd6ab75851b224abf0afe5774976fe511a54d2eb9063a41/zstandard-0.23.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading zstandard-0.23.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Obtaining dependency information for charset-normalizer<4,>=2 from https://files.pythonhosted.org/packages/05/85/4c40d00dcc6284a1c1ad5de5e0996b06f39d8232f1031cd23c2f5c07ee86/charset_normalizer-3.4.2-cp311-cp311-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading charset_normalizer-3.4.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (35 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Obtaining dependency information for urllib3<3,>=1.21.1 from https://files.pythonhosted.org/packages/6b/11/cc635220681e93a0183390e26485430ca2c7b5f9d33b15c74c2861cb8091/urllib3-2.4.0-py3-none-any.whl.metadata\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Obtaining dependency information for jsonpointer>=1.9 from https://files.pythonhosted.org/packages/71/92/5e77f98553e9e75130c78900d000368476aed74276eb8ae8796f65f00918/jsonpointer-3.0.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Downloading langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.58-py3-none-any.whl (437 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.6/437.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading langsmith-0.3.42-py3-none-any.whl (360 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m360.3/360.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl (172 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading sqlalchemy-2.0.40-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.4.2-cp311-cp311-macosx_10_9_universal2.whl (198 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.8/198.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading orjson-3.10.18-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (248 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.9/248.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Downloading zstandard-0.23.0-cp311-cp311-macosx_11_0_arm64.whl (633 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m633.7/633.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Installing collected packages: zstandard, urllib3, tenacity, SQLAlchemy, PyYAML, packaging, orjson, jsonpointer, charset-normalizer, requests, jsonpatch, requests-toolbelt, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.40 charset-normalizer-3.4.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.25 langchain-core-0.3.58 langchain-text-splitters-0.3.8 langsmith-0.3.42 orjson-3.10.18 packaging-24.2 requests-2.32.3 requests-toolbelt-1.0.0 tenacity-9.1.2 urllib3-2.4.0 zstandard-0.23.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d87579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading environment variables \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)  # take environment variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78251eab",
   "metadata": {},
   "source": [
    "The most basic package in the Langchain ecosystem is langchain-core, which contains all classes and abstractions required to build other packages, except LangSmith package.  \n",
    "<img src=\"https://python.langchain.com/assets/images/ecosystem_packages-32943b32657e7a187770c9b585f22a64.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01205b3a",
   "metadata": {},
   "source": [
    "## Learning about Messages\n",
    "In Langchain, each message is defined by a role (e.g., \"user\", \"assistant\") and the content (e.g., text, multimodal data) with additional metadata that varies depending on the chat model provider. LangChain provides a unified message format that can be used across chat models, allowing users to work with different chat models without worrying about the specific details of the message format used by each model provider.\n",
    "\n",
    "### Role \n",
    "Roles are used to distinguish between different types of messages in a conversation and help the chat model understand how to respond to a given sequence of messages.\n",
    "\n",
    "| Role | Description |\n",
    "|---|---|\n",
    "|system|Used to tell the chat model how to behave and provide additional context. Not supported by all chat model providers.|\n",
    "|user|Represents input from a user interacting with the model, usually in the form of text or other interactive input.|\n",
    "|assistant|Represents a response from the model, which can include text or a request to invoke tools.|\n",
    "|tool|A message used to pass the results of a tool invocation back to the model after external data or processing has been retrieved. Used with chat models that support tool calling.|\n",
    "\n",
    "### Langchain Messages \n",
    "SystemMessage: corresponds to system role\n",
    "\n",
    "HumanMessage: corresponds to user role\n",
    "\n",
    "AIMessage: corresponds to assistant role\n",
    "\n",
    "AIMessageChunk: corresponds to assistant role, used for streaming responses\n",
    "\n",
    "ToolMessage: corresponds to tool role\n",
    "\n",
    "RemoveMessage -- does not correspond to any role. This is an abstraction, mostly used in LangGraph to manage chat history.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "720dbc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human Message\n",
      "{\n",
      "  \"content\": \"Hello, I am a human.\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {},\n",
      "  \"type\": \"human\",\n",
      "  \"name\": null,\n",
      "  \"id\": null,\n",
      "  \"example\": false\n",
      "}\n",
      "System Message\n",
      "{\n",
      "  \"content\": \"Hello, I am a system message.\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {},\n",
      "  \"type\": \"system\",\n",
      "  \"name\": null,\n",
      "  \"id\": null\n",
      "}\n",
      "AI Message\n",
      "{\n",
      "  \"content\": \"Hello, I am an AI.\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {},\n",
      "  \"type\": \"ai\",\n",
      "  \"name\": null,\n",
      "  \"id\": null,\n",
      "  \"example\": false,\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": null\n",
      "}\n",
      "AI Message Chunk\n",
      "{\n",
      "  \"content\": \"I am a chunk of AI Message.\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {},\n",
      "  \"type\": \"AIMessageChunk\",\n",
      "  \"name\": null,\n",
      "  \"id\": null,\n",
      "  \"example\": false,\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": null,\n",
      "  \"tool_call_chunks\": []\n",
      "}\n",
      "Removed Message\n",
      "{\n",
      "  \"content\": \"\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {},\n",
      "  \"type\": \"remove\",\n",
      "  \"name\": null,\n",
      "  \"id\": \"123\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, AIMessageChunk, RemoveMessage\n",
    "import json \n",
    "\n",
    "human_message = HumanMessage(\"Hello, I am a human.\")\n",
    "system_message = SystemMessage(\"Hello, I am a system message.\")\n",
    "ai_message = AIMessage(\"Hello, I am an AI.\")\n",
    "ai_message_chunk = AIMessageChunk(\"I am a chunk of AI Message.\")\n",
    "remove_message = RemoveMessage(id=\"123\")\n",
    "\n",
    "print(\"Human Message\")\n",
    "print(human_message.model_dump_json(indent=2))\n",
    "\n",
    "print(\"System Message\")\n",
    "print(system_message.model_dump_json(indent=2))\n",
    "\n",
    "print(\"AI Message\")\n",
    "print(ai_message.model_dump_json(indent=2))\n",
    "\n",
    "print(\"AI Message Chunk\")\n",
    "print(ai_message_chunk.model_dump_json(indent=2))\n",
    "\n",
    "print(\"Removed Message\")\n",
    "print(remove_message.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18248e88",
   "metadata": {},
   "source": [
    "## Prompt Templates\n",
    "Prompt templates help to translate user input and parameters into instructions for a language model. This can be used to guide a model's response, helping it understand the context and generate relevant and coherent language-based output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aab6da46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='Berapa total penjualan produk A')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple Prompt Template\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"Berapa total penjualan produk {name}\")\n",
    "\n",
    "prompt_template.invoke({\"name\":\"A\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b3d454e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a database expert and your task is to write a SQL statement based on a question from user. The SQL query statement shall be executed against an sqlite database.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Berapa total penjualan produk A', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ChatPromptTemplates \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate( [\n",
    "    (\"system\", \"You are a database expert and your task is to write a SQL statement based on a question from user. \"\n",
    "        \"The SQL query statement shall be executed against an sqlite database.\"),\n",
    "    (\"user\", \"Berapa total penjualan produk {name}\")\n",
    "])\n",
    "\n",
    "prompt_template.invoke({\"name\": \"A\"}).to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cfe48711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a database expert and your task is to write a SQL statement based on a question from user. The SQL query statement shall be executed against an sqlite database.', additional_kwargs={}, response_metadata={}),\n",
       " SystemMessage(content='The database contains MthlySales table, with the following columns: ID, PRODUCT_NAME, SALES_QTY, SALES_AMOUNT, MONTH', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Berapa total penjualan produk A', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MessagesPlaceholder \n",
    "# Inserting the whole message instead of keywords.\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "prompt_template = ChatPromptTemplate(\n",
    "    [(\"system\", \"You are a database expert and your task is to write a SQL statement based on a question from user. \"\n",
    "        \"The SQL query statement shall be executed against an sqlite database.\"),\n",
    "      MessagesPlaceholder(\"msg\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt_template.invoke({\"msg\": [SystemMessage(content='The database contains MthlySales table, with the following columns: ID, PRODUCT_NAME, SALES_QTY, SALES_AMOUNT, MONTH'), \n",
    "                                AIMessage(content=\"Berapa total penjualan produk A\")]}).to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b3fa337d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a database expert and your task is to write a SQL statement based on a question from user. The SQL query statement shall be executed against an sqlite database.', additional_kwargs={}, response_metadata={}),\n",
       " SystemMessage(content='The database contains MthlySales table, with the following columns: ID, PRODUCT_NAME, SALES_QTY, SALES_AMOUNT, MONTH', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Berapa jumlah produk A yang terjual di bulan 3', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine them\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "prompt_template = ChatPromptTemplate(\n",
    "    [(\"system\", \"You are a database expert and your task is to write a SQL statement based on a question from user. \"\n",
    "        \"The SQL query statement shall be executed against an sqlite database.\"),\n",
    "      MessagesPlaceholder(\"msg\"),\n",
    "      (\"user\", \"Berapa jumlah produk {name} yang terjual di bulan {month}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt_template.invoke({\"name\":\"A\", \n",
    "                        \"month\":\"3\", \n",
    "                        \"msg\": [SystemMessage(content='The database contains MthlySales table, with the following columns: ID, PRODUCT_NAME, SALES_QTY, SALES_AMOUNT, MONTH')]\n",
    "                        }).to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10563fa6",
   "metadata": {},
   "source": [
    "## Chat Models\n",
    "Chat models are language models that use a sequence of messages as inputs and return messages as outputs (as opposed to using plain text). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ab05fa9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! I'm ChatGPT, an AI language model created by OpenAI. I'm here to assist you with a wide range of topics, answer questions, provide explanations, help with writing, and much more. How can I help you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 10, 'total_tokens': 59, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_79b79be41f', 'id': 'chatcmpl-BTSggYhdsSj4Kjz2MckbkSlwgnTgX', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--788464fb-46f0-49fb-8fc0-04520b63e1a2-0', usage_metadata={'input_tokens': 10, 'output_tokens': 49, 'total_tokens': 59, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-4.1-mini\", model_provider= \"openai\")\n",
    "model.invoke(\"Please introduce yourself\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ee529cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Golden fins that shimmer bright,  \n",
      "Gliding through the silver night,  \n",
      "Moonlit waves in zero gloom,  \n",
      "Dreaming deep—a goldfish moon."
     ]
    }
   ],
   "source": [
    "# How to stream chat model responses\n",
    "\n",
    "for chunk in model.stream(\"Write me a 1 verse song about goldfish on the moon\"):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5038be",
   "metadata": {},
   "source": [
    "## Output Parsers\n",
    "Using the .with_structured_output() method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "531c9e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConceptList(concept='Transformer Architecture', explanation='Transformer architecture is a neural network design that uses self-attention mechanisms to process input data, enabling efficient handling of sequences and is foundational in many generative AI models like GPT and BERT.')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pydantic Class \n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ConceptList(BaseModel):\n",
    "    \"\"\"The list of concepts and brief description\"\"\"\n",
    "    concept: str = Field(description=\"Important concept to be explained.\")\n",
    "    explanation: str = Field(description=\"Brief explanation of the concept\")\n",
    "\n",
    "structured_model = model.with_structured_output(ConceptList)\n",
    "\n",
    "structured_model.invoke(\"I am learning about generative AI. Explain 1 random concept related to it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51888aa5",
   "metadata": {},
   "source": [
    "If you don't want to use Pydantic, explicitly don't want validation of the arguments, or want to be able to stream the model outputs, you can define your schema using a TypedDict class. We can optionally use a special Annotated syntax supported by LangChain that allows you to specify the default value and description of a field. Note, the default value is not filled in automatically if the model doesn't generate it, it is only used in defining the schema that is passed to the model.\n",
    "\n",
    "Requirements\n",
    "\n",
    "> Core: langchain-core>=0.2.26\n",
    "\n",
    "> Typing extensions: It is highly recommended to import Annotated and TypedDict from typing_extensions instead of typing to ensure consistent behavior across Python versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c0a4318d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'concept': 'Transformer Architecture',\n",
       " 'explanation': 'Transformer architecture is a neural network design that uses self-attention mechanisms to process sequences of data, enabling efficient handling of long-range dependencies. It forms the foundation for many generative AI models like GPT, allowing them to generate coherent and contextually relevant text.'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TypedDict \n",
    "\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "class ConceptList(TypedDict):\n",
    "    \"\"\"The list of concepts and brief description\"\"\"\n",
    "    concept: Annotated[str,..., \"Important concept to be explained.\"] # type, default value, and description\n",
    "    explanation: Annotated[str, ... , \"Brief explanation of the concept\"]\n",
    "\n",
    "structured_model = model.with_structured_output(ConceptList)\n",
    "structured_model.invoke(\"I am learning about generative AI. Explain 1 random concept related to it.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8c8e9321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'concept': 'Transformer Architecture',\n",
       " 'explanation': 'The Transformer architecture is a type of deep learning model that uses self-attention mechanisms to process and generate sequences of data, such as text. It enables generative AI models to understand context and produce coherent and contextually relevant outputs.'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JSON Schema\n",
    "# Equivalently, we can pass in a JSON Schema dict. \n",
    "# This requires no imports or classes and makes it very clear exactly how each parameter is documented, \n",
    "# at the cost of being a bit more verbose.\n",
    "\n",
    "json_schema = {\n",
    "    \"title\": \"ConceptList\",\n",
    "    \"description\": \"The list of concepts and brief description\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"concept\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Important concept to be explained.\"\n",
    "        },\n",
    "        \"explanation\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Brief explanation of the concept.\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"concept\", \"explanation\"]\n",
    "}\n",
    "\n",
    "structured_model = model.with_structured_output(json_schema)\n",
    "structured_model.invoke(\"I am learning about generative AI. Explain 1 random concept related to it.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3cb5b5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=ConceptList(concept='Transformer Architecture', explanation='Transformer architecture is a deep learning model architecture introduced in 2017. It uses self-attention mechanisms to process input data sequences, enabling models to understand context and relationships in data effectively. Transformers are foundational in many generative AI systems like GPT, allowing them to generate coherent and contextually relevant text.'))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choosing Multiple Schema\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Union\n",
    "\n",
    "class ConceptList(BaseModel):\n",
    "    \"\"\"The list of concepts and brief description\"\"\"\n",
    "    concept: str = Field(description=\"Important concept to be explained.\")\n",
    "    explanation: str = Field(description=\"Brief explanation of the concept\")\n",
    "\n",
    "class ConversationalResponse(BaseModel):\n",
    "    \"\"\"Respond in a conversational manner. Be kind and helpful.\"\"\"\n",
    "\n",
    "    response: str = Field(description=\"A conversational response to the user's query\")\n",
    "\n",
    "\n",
    "class FinalResponse(BaseModel):\n",
    "    final_output: Union[ConceptList, ConversationalResponse]\n",
    "\n",
    "\n",
    "structured_model = model.with_structured_output(FinalResponse)\n",
    "\n",
    "structured_model.invoke(\"I am learning about generative AI. Explain 1 random concept related to it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9aaa232a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=ConversationalResponse(response=\"As an AI, I don't have feelings or consciousness, but I can share that generative AI technology is a powerful tool with many beneficial applications, such as enhancing creativity, automating tasks, and assisting with problem-solving. However, like all technologies, it also raises important ethical considerations and challenges that society needs to address thoughtfully.\"))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_model.invoke(\"How do you feel about generative AI technology?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f50306c",
   "metadata": {},
   "source": [
    "## Prompt Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2d22ceba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! I’m ChatGPT, an AI language model created by OpenAI. I’m here to help with answering questions, providing explanations, brainstorming ideas, writing assistance, and much more. How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 10, 'total_tokens': 56, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_79b79be41f', 'id': 'chatcmpl-BTVTmIVl9UQhQ2OUMow3bfhk9BPTu', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--d226c97c-e98e-42b1-8b1b-9a7e05812a6f-0', usage_metadata={'input_tokens': 10, 'output_tokens': 46, 'total_tokens': 56, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "# Step 1: Set up the LLM\n",
    "llm = init_chat_model(\"gpt-4.1-mini\", model_provider= \"openai\", temperature = 0.7)\n",
    "llm.invoke(\"Please introduce yourself\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f07d70e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain 1: Summarize input text\n",
    "summarize_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=\"Summarize the following article:\\n\\n{text}\"\n",
    ")\n",
    "\n",
    "summarize_chain = summarize_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6b183221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The article discusses how Artificial Intelligence (AI) is revolutionizing various industries by allowing machines to learn, make decisions, and improve over time. It highlights AI applications like chatbots, virtual assistants, data analytics, and autonomous vehicles. The article also addresses challenges including ethical issues, algorithmic bias, and job displacement. It emphasizes the importance of balancing innovation with responsible development for AI's sustainable success."
     ]
    }
   ],
   "source": [
    "input_text = \"\"\"\n",
    "Artificial Intelligence (AI) is transforming industries by enabling machines to learn from data, \n",
    "make decisions, and even improve over time. Applications range from chatbots and virtual assistants \n",
    "to complex data analytics and autonomous vehicles. However, AI also brings challenges such as ethical concerns, \n",
    "bias in algorithms, and job displacement. As AI continues to evolve, balancing innovation with responsible \n",
    "development will be key to its long-term success.\n",
    "\"\"\"\n",
    "\n",
    "full_response = \"\"\n",
    "for chunk in summarize_chain.stream(input=input_text):\n",
    "    full_response += chunk.content\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3589393f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. What are some key applications of Artificial Intelligence mentioned in the article?  \n",
      "2. What challenges related to AI development does the article highlight?  \n",
      "3. Why does the article emphasize balancing innovation with responsible development in AI?"
     ]
    }
   ],
   "source": [
    "# Chain 2: Generate 3 quiz questions from the summary\n",
    "question_prompt = PromptTemplate(\n",
    "    input_variables=[\"summary\"],\n",
    "    template=\"Based on the summary below, generate 3 quiz questions:\\n\\n{summary}\"\n",
    ")\n",
    "question_chain = question_prompt | llm\n",
    "\n",
    "for chunk in question_chain.stream(input=full_response):\n",
    "    full_response += chunk.content\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "60542bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The article mentions several key applications of Artificial Intelligence (AI) that are revolutionizing various industries:\n",
      "\n",
      "1. **Chatbots:** These AI-powered programs simulate human conversation, enabling businesses to provide instant customer support, answer queries, and improve user engagement without the need for human intervention. Chatbots are widely used in e-commerce, customer service, and information dissemination.\n",
      "\n",
      "2. **Virtual Assistants:** Examples include AI systems like Siri, Alexa, and Google Assistant, which help users perform tasks such as setting reminders, searching the internet, controlling smart home devices, and managing schedules through natural language processing and machine learning.\n",
      "\n",
      "3. **Data Analytics:** AI enhances data analytics by processing vast amounts of data to identify patterns, trends, and insights that humans might miss. This capability aids decision-making, forecasting, and strategic planning in sectors like finance, healthcare, marketing, and manufacturing.\n",
      "\n",
      "4. **Autonomous Vehicles:** AI technologies enable self-driving cars to perceive their environment, make real-time decisions, and navigate safely without human drivers. This application has the potential to transform transportation by improving safety, reducing traffic congestion, and increasing mobility.\n",
      "\n",
      "Overall, these AI applications demonstrate how machines can learn, make decisions, and improve over time, leading to increased efficiency, productivity, and innovation across multiple fields."
     ]
    }
   ],
   "source": [
    "# Chain 3: Answer the first question\n",
    "answer_prompt = PromptTemplate(\n",
    "    input_variables=[\"questions\"],\n",
    "    template=\"Pick the first question from below and answer it in detail:\\n\\n{questions}\"\n",
    ")\n",
    "answer_chain = answer_prompt | llm\n",
    "\n",
    "for chunk in answer_chain.stream(input=full_response):\n",
    "    full_response += chunk.content\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2c174575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since the first question is: \"What are some of the key applications of Artificial Intelligence mentioned in the article?\" I will provide a detailed answer based on general knowledge, as the specific article content is not provided.\n",
      "\n",
      "Artificial Intelligence (AI) has a broad range of applications across various industries. Some of the key applications typically highlighted include:\n",
      "\n",
      "1. **Healthcare:** AI is used for diagnostics, personalized medicine, drug discovery, and robotic surgeries. Machine learning algorithms can analyze medical images to detect diseases like cancer more accurately and faster than traditional methods.\n",
      "\n",
      "2. **Finance:** AI powers fraud detection, algorithmic trading, credit scoring, and personalized financial advice. It helps in analyzing vast amounts of financial data to detect anomalies and forecast market trends.\n",
      "\n",
      "3. **Transportation:** AI enables autonomous vehicles, traffic management systems, and predictive maintenance of vehicles and infrastructure. Self-driving cars use AI to interpret sensor data and navigate safely.\n",
      "\n",
      "4. **Customer Service:** AI chatbots and virtual assistants provide 24/7 customer support, handling inquiries and resolving issues with minimal human intervention.\n",
      "\n",
      "5. **Manufacturing:** AI optimizes production lines through predictive maintenance, quality control, and supply chain management, improving efficiency and reducing downtime.\n",
      "\n",
      "6. **Retail:** AI assists in personalized recommendations, inventory management, and demand forecasting, enhancing the shopping experience and operational efficiency.\n",
      "\n",
      "7. **Natural Language Processing:** AI is used in language translation, sentiment analysis, speech recognition, and content generation, enabling better human-computer interaction.\n",
      "\n",
      "8. **Education:** AI enables personalized learning experiences, automated grading, and educational content creation.\n",
      "\n",
      "These applications demonstrate AI’s transformative potential in improving efficiency, accuracy, and personalization across multiple sectors."
     ]
    }
   ],
   "source": [
    "# Step 2: Compose full chain\n",
    "full_chain = summarize_chain | question_chain | answer_chain\n",
    "\n",
    "for chunk in full_chain.stream(input=input_text):\n",
    "     print(chunk.content, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
